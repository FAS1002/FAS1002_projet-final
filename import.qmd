---
title: "Données"
title-block-banner: true
description: | 
  Cette page regroupe la première importation des données à l'état brute ainsi que les manipulation de bases. 
# à changer
date: "2022-12-21"
# Modifier les détails que vous voulez
author:
  - name: "Juliette Leblanc"
    # Votre site web perso ou github
    url: https://github.com/JulLeblanc
    # les champs d'affiliation sont optionnels, vous pouvez les
    # comment out en ajoutant un # devant.
    affiliation: FAS1002
    affiliation-url: https://FAS1002.github.io/A22
    # changer pour votre propre orcid id
    # https://orcid.org/ pour vous inscrire.
    # orcid: 0000-0000-0000-0000

# TRUE == Générer une citation pour cette page précise. Pour enlever, mettre false.
citation: true
# Inclure les références que vous utilisez dans vos rapports. Je conseille Zotero pour construire
# ce fichier ou de connecter RStudio directement pour pouvoir citer avec @nom-de-reference.
bibliography: references.bib
---

```{r echo=FALSE, warning=FALSE,message=FALSE}

library(tidyverse)
library(fs)
library(lubridate)
library(skimr)
library(countrycode)
```

## Importer les données

#### *Our World in Data* 

J'utilise en premier la banque de données du *Co2 and Greenhouse Gaz Emissions*. Celle-ci sera mis à jour à tous les jours. 
Les données proviennent [d'ici](https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv).
```{r}

unlink("data/raw/*.csv")
unlink("data/raw/*.xlsx")

```


```{r download, cache=TRUE}
#option cache=TRUE c'est si le code ne change pas, il ne devrait pas redownloader le fichier

url_owid <- "https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv"

base_path <- path("data", "raw") # pour que nimporte qui puisse download avec le chemin relatif

fname_owid <- paste(today(), "owid-co2-data.csv", sep = "_") # name the file with today's date

fpath_owid <- path(base_path, fname_owid) 

data_owid <- download.file(url = url_owid, destfile = fpath_owid)

df_owid <- read_csv(fpath_owid)
```

#### *Gapminder*

Pour la deuxième banque de données, je fais appel à celle produite par *Gapminder* qui se nomme *Life Expectancy at Birth*. Celle-ci seront re-téléchargé pour une mise à jour à tous les mois.
Les données proviennent [d'ici]()

```{r}
url_gapminder <- "http://gapm.io/ilex"

base_path <- path("data", "raw")

fname_gap <- paste(today(), "gapm.csv", sep = "_")

fpath_gap <- path(base_path, fname_gap)

data <- download.file(url = url_gapminder, destfile = fpath_gap)

# à changer pas le bon path
df_gapminder <- read_csv("data/raw/life_expectancy_years.csv")
```

#### Joindre les banques de données

Les deux banques de données contiennent une variable commune, soit la variable des pays. Nous allons donc procéder à combiner cette banque de données par leur variable commune, le pays.


```{r}
df_gapminder <- df_gapminder |> 
    pivot_longer(cols = c(2:302),
                 names_to = "year")

df_gapminder <- df_gapminder |> 
    rename(avr_nb_year = value)
```

library(countrycode)
df <- data.frame(country = c("Afghanistan",
                             "Algeria",
                             "USA",
                             "France",
                             "New Zealand",
                             "Fantasyland"))

df$continent <- countrycode(sourcevar = df[, "country"],
                            origin = "country.name",
                            destination = "continent")


Par la suite, nous pouvons regrouper les différents pays ensembles
```{r}
df <- df$country

df$continent <- countrycode(sourcevar = df[, "country"],
                            origin = "country.name",
                            destination = "continent")
```


