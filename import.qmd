---
title: "Données"
title-block-banner: true
description: | 
  Cette page regroupe la première importation des données à l'état brute ainsi que les manipulation de bases. 
# à changer
date: "2022-12-21"
# Modifier les détails que vous voulez
author:
  - name: "Juliette Leblanc"
    # Votre site web perso ou github
    url: https://github.com/JulLeblanc
    # les champs d'affiliation sont optionnels, vous pouvez les
    # comment out en ajoutant un # devant.
    affiliation: FAS1002
    affiliation-url: https://FAS1002.github.io/A22
    # changer pour votre propre orcid id
    # https://orcid.org/ pour vous inscrire.
    # orcid: 0000-0000-0000-0000

# TRUE == Générer une citation pour cette page précise. Pour enlever, mettre false.
citation: true
# Inclure les références que vous utilisez dans vos rapports. Je conseille Zotero pour construire
# ce fichier ou de connecter RStudio directement pour pouvoir citer avec @nom-de-reference.
bibliography: references.bib
---

```{r echo=FALSE, warning=FALSE,message=FALSE}

library(tidyverse)
library(fs)
library(lubridate)
library(skimr)
library(countrycode)
library(cronR)
```

## Importer les données

#### *Our World in Data* 

J'utilise en premier la banque de données du *Co2 and Greenhouse Gaz Emissions*. Celle-ci sera mis à jour à tous les jours. 
Les données proviennent [d'ici](https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv).

À retirer ou ajouter jsp encore:
unlink("data/raw/*.csv")
unlink("data/raw/*.xlsx")


```{r download, cache=TRUE, warning=FALSE, error=FALSE}
#option cache=TRUE c'est si le code ne change pas, il ne devrait pas redownloader le fichier

url_owid <- "https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv"

base_path <- path("data", "raw") # pour que nimporte qui puisse download avec le chemin relatif

fname_owid <- paste(today(), "owid-co2-data.csv", sep = "_") # name the file with today's date

fpath_owid <- path(base_path, fname_owid) 

data_owid <- download.file(url = url_owid, destfile = fpath_owid)

df_owid <- read_csv(fpath_owid)
```

#### *Gapminder*

Pour la deuxième banque de données, je fais appel à celle produite par *Gapminder* qui se nomme *Life Expectancy at Birth*. Celle-ci seront re-téléchargé pour une mise à jour à tous les mois.
Les données proviennent [d'ici]()

```{r cache=TRUE, warning=FALSE, error=FALSE}
url_gapminder <- "http://gapm.io/ilex"

base_path <- path("data", "raw")

fname_gap <- paste(today(), "gapm.csv", sep = "_")

fpath_gap <- path(base_path, fname_gap)

data <- download.file(url = url_gapminder, destfile = fpath_gap)

# à changer pas le bon path
df_gapminder <- read_csv("data/raw/life_expectancy_years.csv")
```

#### Créer une variable

Dans la banque de données de _Our World in Data_, nous avons créer une variable qui regroupe les différents pays en sous-groupe des 5 continents soit : l'Afrique, l'Amérique, l'Asie, l'Europe et l'Océanie. Mais également pour la banque de données du _Life Expectancy_.
```{r}
df_owid <- df_owid |> 
    mutate(continent = countrycode(sourcevar = df_owid$country,
                                   origin = "country.name",
                                   destination = "continent"))

df_gapminder <- df_gapminder |> 
     pivot_longer(cols = c(2:302),
                  names_to = "years")

df_gapminder <- df_gapminder |> 
    mutate(continent = countrycode(sourcevar = df_gapminder$country,
                                   origin = "country.name",
                                   destination = "continent"))
```



#### Joindre les banques de données

Les deux banques de données contiennent une variable commune, soit la variable des pays. Nous allons donc procéder à combiner ces banques de données par leur variable commune, le pays.

```{r}
dat <- full_join(df_gapminder,
                 df_owid,
                 by = "country")
```

## Exporter
Exporter les données traitées dans le dossier data/processed

```{r}
write_csv(df_owid,file = "data/processed/df_owid.csv")

write_csv(df_gapminder, file = "data/processed/df_gapminder.csv")
```


